# PythonbasedVirturalAssistent
In this project, I developed a comprehensive voice and gesture-controlled virtual assistant using Python, integrating various modules for a seamless user experience. The virtual assistant employs pyttsx3 for text-to-speech functionality, speech_recognition for voice recognition, and pyautogui for mouse emulation, providing hands-free control of the computer system.

The project showcases proficiency in computer vision with the implementation of real-time hand gesture recognition utilizing the mediapipe and OpenCV libraries. The assistant responds to both voice commands and hand gestures, offering users a dynamic and interactive interface. Features include opening applications, performing web searches, drawing shapes in Paint, and managing windows through a combination of voice and gesture commands.

Key functionalities include intuitive mouse control through hand movements, allowing users to click, move, and perform various actions effortlessly. The system recognizes specific hand gestures for actions such as opening, closing, and managing windows, offering a unique and efficient interaction paradigm.

This project not only demonstrates technical skills in Python programming but also highlights creativity in combining diverse modules to create an innovative solution. The integration of voice and gesture control contributes to a user-friendly computing experience, providing an alternative means of interaction tailored to user preferences.
